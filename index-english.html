<!doctype html>
<html>
	<head>

		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Aerial Photogrammetry </title>

		<meta name="description" content="Aerial flights and software reconstructions and processing for architecture.">
		<meta name="author" content="Eduardo Chamorro">
				<!-- Chrome, Firefox OS and Opera -->
		<meta name="theme-color" content="#FA7268 ">
			<!-- Windows Phone -->
		<meta name="msapplication-navbutton-color" content="#FA7268 ">
			<!-- iOS Safari -->
		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<meta name="viewport" content="width=device-width, initial-scale=1.0">

		<link rel="stylesheet" href="css/reset.css">
		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/white.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/monokai.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">

				<section data-background-image="img/main6.jpg">
						<h1 style="color: #ffff;">AERIAL PHOTOGRAMMETRY</h1>
						<a  href = "index.html" style="color: #ffff;">Spanish Version</a> <br>
				</section>
 <!--
				<section data-background-image="img/main3.jpg">
						<h1>FOTOGRAMETRÍA AÉREA </h1>
				</section>
-->


			  	<section><!--contenido workshop-->
										<section Set data-background="#FA7268 ">
												<h1>CONTENT</h1>
										</section>
										<section>
												<h2>AERIAL PHOTOGRAPHY</h2>
												<p>We will learn to take data through drones, plan missions, checks and capture techniques</p>
										</section>
										<section>
												<h2>Reconstruction software</h2>
												<p>We will use different photogrammetry software to process the captured data.</p>
										</section>
										<section>
												<h2>Data processing</h2>
												<p>Post-processing of the generated models, analysis and extraction of conclusions.</p>
										</section>
			  	</section>

					<section>
								<section Set data-background="#FA7268 " >
											<h1>PHOTOGRAMMETRY</h1>
											<p style="background-color: #FA7268 ; color: #ffff;">Definition</p><p>Technique to obtain maps and plans of large areas of land through aerial photography.</p>
								</section>


								<section><!--slide2-->
									<h3>500 BC</h3>
									<p>Camera obscura (500 BC in China, 350 BC Aristote, 1000 Al-Haytham, 1500 Léonard de Vinci)
									</p>
									<img height="500" data-src="img/camera_obscura.jpg" alt="Down arrow">
								</section>

								<section><!--slide4-->
									<h3>~1500</h3>
									<p>Leonardo Da Vinci tries to determine the painter's point of view from the perspective of painting.</p>
									<img height="500" data-src="img/davinici.png" alt="Down arrow">
								</section>

								<section><!--slide5-->
									<h3>~1600</h3>
									<p>Camera lucida (patented by Wollaston in 1806)</p>
									<img height="500" data-src="img/camera_lucida.jpg" alt="Down arrow">
								</section>

								<section><!--slide6-->
									<h3>1793</h3>
									<p>Beautemps-Beaupré, hydrography: maps of shorelines during expeditions from angular and distance measurements</p>
									<img height="500" data-src="img/beautemps_beaupre.jpg" alt="Down arrow">
								</section>

								<section><!--slide7-->
									<h3>1826</h3>
									<p>Niépce, First photography</p>
									<img height="500" data-src="img/first_photography_niepce.jpg" alt="Down arrow">
								</section>

								<section><!--slide3-->
									<h3>1836</h3>
									<p>Daguerreotype - "gift to the world" from the French Academy</p>
									<img height="500" data-src="img/daguerre_process.jpg" alt="Down arrow">
								</section>
								<section><!--slide3-->
									<h3>1911</h3>
									<p>Scheimpflug, first aerial photogrammetry, rectified photographs.</p>
									<img height="200" data-src="img/pigeon_photos_ww.jpg" alt="Down arrow">
										<img height="200" data-src="img/pigeon_ww.jpg" alt="Down arrow">
								</section>

										<section>
													  <h3 class="text-center">Emergence of Mathematical Solutions</h3>
							                <ul>
							                    <li>
							                        3D pose problem
							                        <ul>
							                            <li>1615 - Snellius</li>
							                            <li>1773 - Lagrange</li>
							                            <li>1841 - Grunert</li>
							                        </ul>
							                    </li>
							                    <li>
							                        Epipolar geometry
							                        <ul>
							                            <li>1862 - Terrero</li>
							                            <li>1883 - Hauck</li>
							                            <li>1899 - Finsterwalder</li>
							                        </ul>
							                    </li>
							                    <li>
							                        Trifocal geometry
							                        <ul>
							                            <li>1883 - Hauck</li>
							                        </ul>
							                    </li>
							                    <li>
							                        Motion estimation
							                        <ul>
							                            <li>1880 - Schroter: 4 point problem for coplanar object points</li>
							                            <li>1913 - Kruppa: 5 point problem</li>
							                            <li>2003 - Nister: first algorithm for the 5 point problem that gives at most 10 solutions</li>
							                        </ul>
							                    </li>
							                    <li>
							                        3D modeling from a single image
							                        <ul>
							                            <li>~1800 - Laussedat</li>
							                            <li>1883 - Hauck</li>
							                            <li>1892 - Meydenbauer</li>
							                        </ul>
							                    </li>
							                    <li>
							                        3D reconstruction from uncalibrated images &amp; projective reconstruction
							                        <ul>
							                            <li>1883 - Hauck</li>
							                            <li>1899 - Finsterwalder</li>
							                        </ul>
							                    </li>
							                    <li>
							                        Camera self-calibration
							                        <ul>
							                            <li>1892 - Meydenbauer</li>
							                            <li>1899 - Finsterwalder</li>
							                        </ul>
							                    </li>
							                </ul>
												</section> <!--BASES FOTOGRAFIA AREA--><!--MATEMATHICAL SOLUTIONS-->
											</section>
					</section><!--Historia fotogrametria-->	<!--Fotogrametrias-->



					<section>
										  	<section Set data-background="#FA7268 " >
													<h1>FOTOGRAFIA AEREA</h1>
													<p style="background-color: #FA7268 ; color: #ffff;">Definition</p><p>Analysis of the Earth's surface by using photographic machines installed on board various aerial media.</p>
												</section>
												<section>
														<h4 style="background-color: #FA7268 ; color: #ffff;">The process consists of the flight and capture of photographs in the first place.</h4>
														<p>These images are then processed using specific programs to obtain 3D and Orthomosaic models.With this type of program, it is possible to obtain an accuracy of up to 1 centimeter in planimetry thanks to the inclusion, as we have commented in the example, of support points taken by GNSS topographic. The obtained orthomosaics can reach up to 1 centimeter of GSD (Ground Sample Distance), that is, one pixel of the generated image represents a square of 1 centimeter on each side in reality. Ideal specifications.

													</p>
												</section>
												<section>
													<h2>Safety</h2>
													<ul>
														<li>The security of the surveyor, the most notable advantage. Before, the surveyor needed to be able to take material collection points, so he had to ascend to the highest level of this, travel a steep slope to be able to represent it, etc. with the possibility of slipping or with the unfortunate result of sinking into storage.</li>
													</ul>
													<h2>Efficiency</h2>
													<ul>
														<li>Through the drone flight you can get millions of colored points; whereas before, the surveyor had to observe point by point, obtaining only coordinates in which he could hardly achieve 500 points per day.</li>
													</ul>
											 </section>
											 	<section>
													<h2>Visual value</h2>
													<ul>
														<li>The possibility of having a graphic document with a history is born in which the progress can be seen as a possible guarantee for future claims or simply for a visual analysis. In this way, it is possible to visually compare the quantity of material that has changed in a warehouse.</li>
													</ul>
													<h2>Immediacy</h2>
													<ul>
														<li>It is possible to reduce the processing time and, therefore, the labor costs decrease. Years ago, photogrammetric flights using planes specifically adapted to this job gave delivery times of approximately 1 month. Through a drone flight and taking support points, this time is reduced to days.</li>
													</ul>
											 </section>
											 <section>
													<h2>Restrictions</h2>
													<ul>
														<li>It is limited by the law in force in Spain. Currently this distance is marked 500m away from the takeoff point for a BVLOS flight for a drone between 2 and 25kg.</li>
													</ul>
													<h2>Altura</h2>
													<ul>
														<li>The maximum height. As in the previous point, the maximum height is limited in Spain to 120 meters.</li>
													</ul>
											 </section> <!--BASES FOTOGRAFIA AREA-->
					</section>	<!--fotografia aerea beneficios-->

				  <section>	<!--PASOS A SEGUIR-->
						 							<section>
														<h2 >HOW TO TAKE THE DATA</h2>
														<p>We must make a linear or orbital flight around the model to rebuild</p>
														<img height="500" data-src="img/around.jpg" alt="Down arrow">
													</section>

												<section>
														<h2>Steps to follow</h2>
													<ul>
														<li>FLIGHT PLANNING</li>
														<img height="150" data-src="img/strategy-100x100.png" alt="Down arrow">
														<li>TOPOGRAPHIC SUPPORT</li>
														<img height="150" data-src="img/map-location-100x100.png" alt="Down arrow">
													</ul>
												</section>
												<section>
														<h2>Steps to follow</h2>
													<ul>
														<li>FLIGHT PERFORMANCE</li>
														<img height="150" data-src="img/drone-100x100.png" alt="Down arrow">
														<li>PROCESSING AND CALCULATION</li>
														<img height="150" data-src="img/internet-100x100.png" alt="Down arrow">
													</ul>
												</section>
					</section>

					<section><!--planeando el vuelo-->
									<section>
												<h2 style="background-color: #FA7268 ; color: #ffff;">TYPE OF DATA COLLECTION</h2>
												<p>It is necessary to establish a strategy adapted to each model to be reconstructed</p>
												<a href = "https://www.youtube.com/watch?v=q3wXggCqY_8">Plan the flight</a> <br>
									</section>
									<section >
												<h2>MULTIPOSITION</h2>
												<img height="400" data-src="img/tipos/epipolar_geometry.jpg" alt="Down arrow">
												<p>Es necesario que las imagenes tomadas tengan distintos angulos de toma y perspectiva entre ellas para asi poder reconstruir una superficie no bidimensional.</p>
									</section>
									<section >
										<h2>REFERENCED</h2>
										<img height="400" data-src="img/tipos/1.jpg" alt="Down arrow">
										<p>Al superponer fotografias en distintas posiciones los softwares de reconstrucion puede cuadrar matrices de puntos de referencia para asi ubicar primero donde fueron tomadas las fotografias y luego comenzar la reconstruccion.</p>
									</section>
											<section >
												<h2>OVERLAP</h2>
													<p>Es recomendable que las fotografia se solapen en la imagen tomada al menos un 20-30% siendo recomendable hasta un 60%.</p>
													<img height="400" data-src="img/tipos/superpo.jpg" alt="Down arrow">
											</section>
											<section >

													<img height="400" data-src="img/tipos/solape.jpg" alt="Down arrow">
											</section>
											<section >
												<h2>DOME SHOT</h2>
														<p>Used when there is a main element to rebuild but still maintains interest in the surroundings.</p>
													<img height="400" data-src="img/tipos/cupula.jpg" alt="Down arrow">
											</section>
											<section >
												<h2>CYLINDRICAL SHOT</h2>
													<p>Used in small-scale models or in high-rise towers.</p>
													<img height="400" data-src="img/tipos/cilindrico.jpg" alt="Down arrow">
											</section>
											<section >
												<h2>ORBITAL SHOT</h2>
													<p>Utilizada cuando existe un elemento principal en la composicion y se pretende la mayor definicion de este y no su entorno.</p>
													<img height="400" data-src="img/tipos/orbital.jpg" alt="Down arrow">
											</section>
											<section >
												<h2>SWEPT</h2>
													<p>Typology used with the double sweep to obtain models of great precision and detail</p>
													<img height="400" data-src="img/tipos/barrido.jpg" alt="Down arrow">
											</section>
											<section >
												<h2>EXTENSION SHOT</h2>
													<p>Mainly used in agriculture for crop control, it is usually done with flying wing type drones as they give greater autonomy</p>
													<img height="400" data-src="img/tipos/extension.jpg" alt="Down arrow">
											</section>
											<section >
												<h2>ZIGZAG SHOT</h2>
													<p>This type of intake is usually the most used in manual flights and small extension since it allows great overlap while maintaining simple trajectories</p>
													<img height="400" data-src="img/tipos/zizaghd.jpg" alt="Down arrow">
											</section>

					</section>

										<section><!--dji control-->
														<section>
																	<h2 style="background-color: #FA7268 ; color: #ffff;">DJI - DRONE CONTROL</h2>
																	<p>Flight programming of</p>
																	<a href = "https://www.dji.com/es/mavic-mini">Mavic-Mini</a> <br>
														</section>
														<section data-background-image="img/dji/1.jpg">
																<h1 style="color: #ffff;">EASY AREAL PLATFORM </h1>
														</section>
														<section >
															<h2>SIMPLIFIED CONTROLS</h2>
															<p>With the smartphone we can see our flight route, coordinates and different recording options.</p>
															<img height="400" data-src="img/dji/2019-11-11-DJI-Go-4-UI.png" alt="Down arrow">
														</section>
														<section data-background-video="img/dji/vid1.mp4"><h2 style="text-align: left;"></h2><!--,video.webm--></section>
														<section >
															<h2>LET´S USE IT</h2>
															<p>Turn on the drone and the controller connected to the smartphone and start the DJI-FLY application</p>
															<img height="400" data-src="img/dji/DJI-Mavic-Mini-Firmware-Update-Available.png" alt="Down arrow">
														</section>
														<section >
															<h2>FIRMWARE UPDATES</h2>
															<p>Always install the latest updates as they include important flight improvements</p>
															<img height="400" data-src="img/dji/DJI-Mavic-Mini-Firmware-Updated.png" alt="Down arrow">
														</section>
														<section >
															<h2>CONFIGURATIONS</h2>
															<p>The configuration menu is in the upper right corner</p>
															<img height="400" data-src="img/dji/SETTINGS.png" alt="Down arrow">
														</section>
														<section >
															<h2>CONFIGURATIONS</h2>
															<p>With the safety settings we adjust the maximum distance and height it can reach and the automatic return height.</p>
															<img height="400" data-src="img/dji/DJI-Mavic-Mini-Safety-Settings-Tab.png" alt="Down arrow">
														</section>
														<section >
															<h2>CONFIGURATIONS</h2>
															<p>Recommended to fly in position or in cinemasoth (slowly) if the place to fly has many obstacles.</p>
															<img height="400" data-src="img/dji/DJI-Mavic-Mini-Controls-Settings.png" alt="Down arrow">
														</section>
														<section >
															<h2>CONFIGURATIONS</h2>
															<p>In image adjustments we will choose the 4: 3 ratio since it gives us more vertical and is the original ratio of the camera sensor</p>
															<img height="400" data-src="img/dji/DJI-Mavic-Mini-Aspect-Ratio-Settings-.png" alt="Down arrow">
														</section>
														<section >
															<h2>CONFIGURATIONS</h2>
															<p>In advanced settings we will choose to show a video gang to allow us to better frame the images.</p>
															<img height="400" data-src="img/dji/DJI-Mavic-Mini-Camera-Overlays-1.png" alt="Down arrow">
														</section>
														<section >
															<h2>CONFIGURATIONS</h2>
															<p>Always before flying we must check that our broadcast channel is free of interference or we risk easily losing the connection and control of the drone.</p>
															<img height="400" data-src="img/dji/DJI-Mavic-Mini-Transmission-Page.png" alt="Down arrow">
														</section>
														<section >
															<h2>FLIGHT</h2>
															<p>The controls on the left side are all automatisms such as the automatic takeoff, where the drone rises up to 1.5m high</p>
															<img height="400" data-src="img/dji/DJI-Mavic-Mini-Take-Off.png" alt="Down arrow">
														</section>
														<section >
															<h2>FLIGHT</h2>
															<p>In the visual interface in the lower left corner we will see a map if we double click on it, it will be displayed allowing us to observe the map</p>
															<img height="400" data-src="img/dji/DJI-Mavic-Mini-Pre-Take-off.png" alt="Down arrow">
														</section>
														<section >
															<h2>FLIGHT</h2>
															<p>Here we can observe dangerous or prohibited flight zones and the trajectory that the drone is making.</p>
															<img height="400" data-src="img/dji/2019-12-19-12.50.04.png" alt="Down arrow">
														</section>
														<section >
															<h2>FLIGHT</h2>
															<p>Here we can observe dangerous or prohibited flight zones and the trajectory that the drone is making.</p>
															<img height="400" data-src="img/dji/DJI-Mavic-Mini-Map-View.png" alt="Down arrow">
														</section>
														<section >
															<h2>FLIGHT</h2>
															<p>On the left side there are also the buttons for landing and return to the automatic take-off point</p>
															<img height="400" data-src="img/dji/DJI-Mavic-Mini-Return-To-Home.png" alt="Down arrow">
														</section>

														<section >
																	<h2>CAMERA SETTINGS</h2>
																	<img height="400" data-src="img/dji/2019-12-19-12.57.57.png" alt="Down arrow">
																	<p>On the right side we have the option to choose between photography and video</p>
														</section>
													 <section >
																 <h2>CAMERA SETTINGS</h2>
																 <img height="400" data-src="img/dji/2019-12-19-12.58.01.png" alt="Down arrow">
																 <p>During the flight you can choose between photo with timer or in manual mode</p>
													 </section>
													 <section >
																 <h2>CAMERA SETTINGS</h2>
																 <img height="400" data-src="img/dji/DJI_Mavic-Mini-Exposure-Compensation.png" alt="Down arrow">
																 <p>It is very important to choose the correct lighting and lock the exposure control whenever possible.</p>
													 </section>
													<section data-background-video="img/dji/vid2.mp4"><h2 style="text-align: left;"></h2><!--,video.webm--></section>



										</section>


					<section><!--mission planer-->
									<section>
												<h2 style="background-color: #FA7268 ; color: #ffff;">OPEN CONTROL - MISSION PLANER</h2>
												<p>Flight program and open source programming</p>
												<a href = "http://ardupilot.org/planner/">Ardupilot</a> <br>
									</section>
									<section >
												<h2>MULTIPOURPOSE</h2>
												<img height="400" data-src="img/mi/1.jpg" alt="Down arrow">
												<p>This software serves both to program drones, as well as to adjust them, create missions and see their location in real time</p>
									</section>
									<section >
										<p>In the flight plan section we can establish our flight route, coordinate and what will be done in each position.</p>
										<img height="400" data-src="img/mi/2.jpg" alt="Down arrow">
									</section>
											<section >
												<h2></h2>
													<p>Depending on the place we must choose a different cartographic base, here we can see the comparison of gooogle maps vs bing maps</p>
													<img height="400" data-src="img/mi/3.jpg" alt="Down arrow">
											</section>
											<section >
												<h2>HOME</h2>
														<p>Establish a base point (home) that will serve as a reference and recovery.</p>

													<img height="400" data-src="img/mi/4.jpg" alt="Down arrow">
											</section>
											<section >
												<h2>Scanning area</h2>
														<p>Draw a polygon of what will be our area to scan.</p>
													<img height="400" data-src="img/mi/5.jpg" alt="Down arrow">
											</section>
											<section >
												<h2>AUTO WAYPOINT </h2>
													<p>Right button autowp and in this case we will use "survey".</p>
													<img height="400" data-src="img/mi/6.jpg" alt="Down arrow">
											</section>
											<section >
												<h2>Camera Menu</h2>
													<p>Adjust the camera used, overlap, height and type of route</p>
													<img height="400" data-src="img/mi/7.jpg" alt="Down arrow">
											</section>
											<section >
												<h2>WP´S EXPORT </h2>
													<p>Check the waypoints and save the file to the drone</p>
													<img height="400" data-src="img/mi/8.jpg" alt="Down arrow">
											</section>
					</section>


					<section Set data-background="#FA7268 " >
								<h1>RECONSTRUCTION</h1>
								<p style="background-color: #FA7268 ; color: #ffff;">Definicion</p><p>Photogrammetric frame of artificial vision for 3D reconstruction and camera tracking.</p>
					</section>
					<section><!--meshroom-->
									<section>
												<h2 style="background-color: #FA7268 ; color: #ffff;">Meshroom/AliceVision</h2>
												<p>Meshroom is a free open source photogrammetry software with a beautiful user interface. It is built on an underlying framework called AliceVision, which is the result of cooperation between multiple Universities and laboratories.</p>
												<a href = "https://alicevision.github.io/">Meshroom Download</a> <br>
									</section>
									<section >
												<h2>Simple and intuitive interface</h2>
												<img height="400" data-src="img/meshroom.png" alt="Down arrow">
												<p>The basic interaction is as simple as possible. Drag and drop the images into the Meshroom window, press START and wait for the model to finish.</p>
									</section>
									<section data-background-iframe="https://www.youtube.com/embed/v_O6tYKQEBA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
										</section>
									<section >
										<h2>Two steps- Drag and Drop</h2>
										<img height="400" data-src="img/gifmeshroom.gif" alt="Down arrow">
									</section>
									<section >
												<h2>Standard Reconstruction</h2>

												<p>Chances are, you use the standard reconstruction when processing photos taken previously outside, and you can't just take more of them. We assume that you have already taken all the necessary photos, arrived home and now want to rebuild the 3D model.</p>
									</section>
									<section>
												<h2>the workflow is very simple</h2>
												<ul>
													<li>Copy all the images to a folder on your hard drive</li>
													<li>Drag and drop the folder (or individual images) into the Meshroom window</li>
													<li>Save the project using File - Save to a destination of your choice (otherwise the reconstruction will be stored in a temporary folder)</li>
													<li>Press Start or right-click the Structure From Motion (SFM) node and press Calculate</li>
													<li>
														Wait taking a coffee
													</li>
												</ul>
											</section>
											<section >
													<p>If you notice that a significant number of images were discarded and the preview has only a few cameras, there is little point in continuing with the reconstruction.</p>
													<img height="400" data-src="img/bad_photos.jpg" alt="Down arrow">
											</section>
											<section >
													<p>After the complete rebuild is complete, you can double-click the Textured node to preview the final mesh.</p>
													<img height="400" data-src="img/meshroom.jpg" alt="Down arrow">
											</section>
											<section >
													<p>You can right-click on any of the completed nodes and select Open Folder. Open the texture or filter mesh folder to find the output file in a commonly used Wavefront .obj format.</p>
													<img height="400" data-src="img/1.jpg" alt="Down arrow">
											</section>

					</section>
					<section><!--recap-->
									<section>
												<h2 style="background-color: #FA7268 ; color: #ffff;">Autodesk Recap Photo</h2>
												<p>Autodesk recap is a photogrammetric reconstruction software that operates in the cloud, all calculations are done by Autodesk servers.</p>
												<a href = "https://www.autodesk.com/products/recap/overview">Autodesk ReCap Photo Download</a> <br>
									</section>
									<section >
												<h2>Simple and intuitive interface</h2>
												<img height="400" data-src="img/recap/0.jpg" alt="Down arrow">
												<p>It has a minimalist interface to make the whole process as transparent as possible to the user. It is only necessary to upload the photos to the server and in a few hours we will have the model ready</p>
									</section>
									<section data-background-iframe="https://www.youtube.com/embed/jups9i9fKvQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
										</section>
									<section >
										<h2>Voila! The already rebuilt model ready to upgrade and export</h2>
										<img height="400" data-src="img/recap/1.jpg" alt="Down arrow">
									</section>
											<section >
												<h2>IMPROVEMENT</h2>
													<p>The first tool allows us to model the ¨mesh¨ as clay to make small corrections and fixes for elements that have not been properly reconstructed</p>
													<img height="400" data-src="img/recap/2.jpg" alt="Down arrow">
											</section>
											<section >
														<p>The bottom menu allows us to change display styles, wireframe, texturing, camera locations and rendering types.</p>
													<img height="400" data-src="img/recap/3.jpg" alt="Down arrow">
											</section>
											<section >
													<p>With untextured visualizations we can better correct model errors and observe and modify the plot density.</p>
													<img height="400" data-src="img/recap/4.jpg" alt="Down arrow">
											</section>
											<section >
													<p>With the already exported and textured model we can work and analyze it on other platforms</p>
													<img height="400" data-src="img/recap/valldaura.png" alt="Down arrow">
											</section>

					</section>
					<section><!--recap-->
									<section>
												<h2 style="background-color: #FA7268 ; color: #ffff;">Agisoft Photoscan</h2>
												<p>Agisoft PhotoScan is a professional photogrammetric reconstruction software, it gives a great final quality and integrates multiple post-processes.</p>
												<a href = "https://www.agisoft.com/">Agisoft Download</a> <br>
									</section>

								  <section data-background-video="img/agi/2.mp4"><h2 style="text-align: left;">Agisoft Photoscan</h2><!--,video.webm--></section>
								  <section >
												<h2>INICIO</h2>
												<img height="400" data-src="img/agi/1.jpg" alt="Down arrow">
												<p>We proceed to load the photo bases "ADD CHUNK"</p>
									</section>
									<section >
										<h2>START</h2>
										<img height="400" data-src="img/agi/2.jpg" alt="Down arrow">
										<p>We proceed to attach the photographs taken "add photos"</p>
									</section>
											<section >
												<h2>First processed</h2>
													<p>We proceed to start the alignment of the photographs is a relatively fast process where the cameras are placed in space</p>
													<img height="400" data-src="img/agi/3.jpg" alt="Down arrow">
											</section>
											<section >
													<h2>Cameras aligned</h2>
  														<p>  If you have a large number of images (more than 100), we recommend to enable - Generic preselection option, to reduce processing time;</p>
  														<p>  We do not recommend using parameters: Guided image matching, Adaptive camera model fitting;</p>
  														<p>  For Key point limit the recommended range of 20 000 to 100 000;</p>
  														<p>  For Tie point limit the recommended range of 2 000 to 40 000.</p>
													<img height="400" data-src="img/agi/sHo8Zk-NncOB6R7avdYoLx2d_y67tEzEDQ.png" alt="Down arrow">
											</section>
											<section >
													<h2>Cameras aligned</h2>
														<p>We can already see a basic mesh where the photographs have been placed and a basic point cloud</p>
													<img height="400" data-src="img/agi/4.jpg" alt="Down arrow">
											</section>
											<section >
													<p>In this step we can eliminate the cameras that have not been located correctly or that bother us</p>
													<img height="400" data-src="img/agi/5.jpg" alt="Down arrow">
											</section>
											<section >
													<p>After photo alignment is finished, refine bounding box position and orientation to fit the desired volume for reconstruction:</p>
													<img height="400" data-src="img/agi/j3Qco4DMBi-6Ix-VmfrJupEw4ud2JVPa7Q.png" alt="Down arrow">
											</section>
											<section >
												<h2>Point cloud calculation</h2>
													<p>The point cloud is a three-dimensional representation of points in which each point also includes texture. It is this step that determines the quality.</p>
													<img height="400" data-src="img/agi/6.jpg" alt="Down arrow">
											</section>
											<section >
													<p>We recommend to use </br>
														- Medium quality. </br>
														Higher quality takes quite a long time and demands more computational resources, but allows for more detailed results generation.</br>
														If the geometry of the scene to be reconstructed is complex with numerous small detail on the foreground, then it is recommended to set Mild depth filtering mode, for important features not to be sorted out). </p>
											</section>
											<section >
													<p>Select Build Dense Cloud command from the Workflow menu. Set the following recommended values for the parameters in the Build Dense Cloud dialog:</p>
													<img height="400" data-src="img/agi/vDPyJAyPSgXDr775Wz7aMquMqqIkHyYVew.png" alt="Down arrow">
											</section>
											<section >
													<p>Once this step is finished we can already see perfectly our model represented in points, many editors prefer to work with this format as it is more flexible and light</p>
													<img height="400" data-src="img/agi/7.jpg" alt="Down arrow">
											</section>
											<section >
													<p>Points from the dense cloud can be removed with the help of selection tools and Delete/Crop instruments located on the Toolbar.</p>
													<img height="400" data-src="img/agi/selection.jpg" alt="Down arrow">
											</section>

											<section >
													<h2>Mesh calculation</h2>
													<p>From the points we can create triangulated surfaces to represent "MESH" reality on surfaces.</p>
													<img height="400" data-src="img/agi/8.jpg" alt="Down arrow">
											</section>
											<section >
													<p>After dense point cloud has been reconstructed it is possible to generate polygonal mesh model based on the dense cloud data or depth maps data. The second approach supports GPU-acceleration and mostly provides better results for the same depth maps quality for objects and scenes with big number of minor details.</p>

											</section>
											<section >
													<p>Select Build Mesh command from the Workflow menu. Set the following recommended values for the parameters in the Build Mesh dialog:</p>
													<img height="400" data-src="img/agi/ijjIiZhCZDfl4WTnhP0oHP9V86XfJ2-_ig.png" alt="Down arrow">
											</section>

												<section >
													<p>This type of representation is what we commonly know as 3D and we can export it to multiple programs.</p>
													<img height="400" data-src="img/agi/11.jpg" alt="Down arrow">
											</section>

											<section >
													<h2>Build Texture</h2>
													<img height="400" data-src="img/agi/QBbi2UlmlpUc24ZWC9_vn6eDHY4KVFg31g.png" alt="Down arrow">
											</section>
											<section >
												<p>Usually the texture atlas size in range of 4000 - 10000 pixels is sufficient. </p>
										</section>
										<section data-background-iframe="https://sketchfab.com/models/52c59d0c00d3477db5f44f274356da57/embed?autostart=1"frameborder="0"  allow="autoplay; fullscreen; vr" mozallowfullscreen="true" webkitallowfullscreen="true">
										</section>
										<section ><h2>Export</h2>
											<img height="400" data-src="img/agi/FRmxxHsNokFe2MTFNf0D3RqCpS7dZtqBTQ.png" alt="Down arrow"></br>
											- <a href ="https://www.pointbox.xyz/" >POINT CLOUDS ONLINE</a> <br>
											- <a href ="https://sketchfab.com/feed" >3D Mesh models</a> <br>

									</section>


					</section>

					<section style="text-align: left;">
								<h1 >GENERATED DATA</h1>
								<h3><p>
									- <a href ="https://drive.google.com/drive/folders/1sRrrFw-SHCYs2MrV8wTH-1pFA1riVbr0?usp=sharing" >Workpackage-TestModel-Agisoft</a> <br>
									- <a href ="Codes/TestFiles.rar" >All files</a> <br>
									- <a href ="Codes/TestFiles/valldaura.obj" >Obj-Sample</a> <br>
									- <a href="Codes/TestFiles/valldaura.mtl">MTL-Sample</a><br>
									- <a href="Codes/TestFiles/valldaura.png">Image-Sample</a><br>
									- <a href="Codes/TestFiles/valldaura01.jpg">Textures-Sample</a><br>
									- <a href="Codes/TestFiles/DisplacementMap_1.jpg">Displacement-Sample</a><br>
									- <a href="Codes/TestFiles/NormalMap_1.jpg">NormalMap-Sample</a><br>
								</p></h3>
					</section>


					<section Set data-background="#FA7268 " >
								<h1>POST-PROCESSED</h1>
								<p style="background-color: #FA7268 ; color: #ffff;">Definicion</p><p>Treatment of a series of data to extract models, conclusions or effects not obtained in the first place.</p>
					</section>

					<section>
										<section>
													<h2 style="background-color: #FA7268 ; color: #ffff;">Data processing</h2>
													<p>Post-processing of the generated models, analysis and extraction of conclusions.</p>
										</section>
										<section>
													<h2>DATABASE - TO ANALYSIS</h2>
													<p>From the textured three-dimensional model (mesh or point cloud) we can extract multiple types of data and maps</p>
													<img height="400" data-src="img/3sites.png" alt="Down arrow">
										</section>
										<section>
													<h2>Geometric data</h2>
													<p>We can do both area and volume analysis, characterizing both its geometry and its typology.</p>
													<img height="400" data-src="img/stockpile.jpg" alt="Down arrow">

										</section>
										<section>
													<h2>MEASUREMENTS</h2>
													<p>Measurements and distances over places with little or no information</p>
													<img height="400" data-src="img/medir.jpg" alt="Down arrow">
										</section>

										<section>
													<h2>Visualizations</h2>
													<p>Creation of photomontages or interactive videos from the reconstructed model or as a basis for situating interventions</p>
													<img height="400" data-src="img/r.gif" alt="Down arrow">
										</section>
										<section>
													<h2>Live data</h2>
													<p>Analysis of situations in emergency contexts for planning interventions</p>
													<img height="400" data-src="img/00.png" alt="Down arrow">
										</section>
										<section>
													<h2>Estudios</h2>
													<p>Analysis of crops and vegetation</p>
													<img height="400" data-src="img/ndre.jpg" alt="Down arrow">
										</section>
					</section>


					<section>
									<section>
											<h2 style="background-color: #FA7268 ; color: #ffff;">D-E-M</h2>
											<p>DIGITAL ELEVATION MAP ANALYSIS</p>
									</section>
									<section >
										<h2>DEM</h2>
										<p>DIGITAL ELEVATION MAP es una forma de representacion de nuestro modelo por altura en las cotas Z se cambian los colores de las texturas por colores de altura</p>
										<img height="400" data-src="img/agi/9.jpg" alt="Down arrow">
									</section>
									<section data-background-image="img/DEM.jpg">
									</section>
					</section>


				<section >
									<section>
											<h2 style="background-color: #FA7268 ; color: #ffff;">ORTOMOSAIC</h2>
											<p>Photographic representation of an area of the earth's surface, in 2d</p>
									</section>
									<section >
										<h2>ORTOMOSAIC</h2>
										<p>As with DEM we can also extract an HD photographic composition of the model (Commonly known as google maps style).</p>
										<img height="400" data-src="img/agi/10.jpg" alt="Down arrow">
									</section>
									<section data-background-image="img/Orto.jpg">
									</section>
				</section>

				<section style="text-align: left;">
					<h1 >Downloads</h1>
				<h3><p>
						-	<a href="https://drive.google.com/open?id=1Fno3T7ecltDLdVdVXoAaAI-1PlgsUDox">Ceu Photographic Base</a><br>
						-	<a href="Codes/UpsCeuTerrainPointCloudLIGHT.pts">Cloud Point Model</a><br>
						-	<a href="Codes/UspCeuMesh.rar">Mesh Model</a><br>
						- <a href ="Codes/Plugins-Photogrammetry.rar">PluginsGrasshopper fotogrametria</a> <br>
						- <a href="Codes/GrasshopperCodes.rar">Grasshopper Scripts</a><br>

					</p></h3>
				</section>

				<section>
					<h2>Plugin installation</h2>
					<p>Grasshopper plugins that do not come with an .exe file are installed manually.</p>
					<ul>
						<li>Let's go to File- special folders-ComponentFolder</li>
						<li>Open the special folder "Components Folder"</li>
						<li>Copy the plugin files into this folder</li>
						<li>Unlock each file by right-clicking it -> Properties</li>
						<li>Reopen Rhino and Grasshopper</li>
					</ul>
				</section>





				<!----
				<section >
					<h2>Clever Quotes</h2>
					<p>
						These guys come in two forms, inline: <q cite="http://searchservervirtualization.techtarget.com/definition/Our-Favorite-Technology-Quotations">The nice thing about standards is that there are so many to choose from</q> and block:
					</p>
					<blockquote cite="http://searchservervirtualization.techtarget.com/definition/Our-Favorite-Technology-Quotations">
						&ldquo;For years there has been a theory that millions of monkeys typing at random on millions of typewriters would
						reproduce the entire works of Shakespeare. The Internet has proven this theory to be untrue.&rdquo;
					</blockquote>
				</section>--->
				<section data-background-video="img/ceu.mp4"><!--,video.webm-->
				<h2 style="text-align: left;">Output-Data</h2></section>
				<section data-background-iframe="https://sketchfab.com/models/e6271319d80443d4af3d24e7a39553d1/embed?autostart=1"frameborder="0"  allow="autoplay; fullscreen; vr" mozallowfullscreen="true" webkitallowfullscreen="true">
				</section>

				<section data-background-video="img/flight.mp4"><!--,video.webm-->
				<h2 style="text-align: left;">Output-Data</h2></section>

				<section data-background-iframe="https://sketchfab.com/models/951466585a424860ae8d05fc85c47d14/embed?autostart=1"frameborder="0"  allow="autoplay; fullscreen; vr" mozallowfullscreen="true" webkitallowfullscreen="true">
				</section>

				<section data-background-iframe="http://eduardochamorro.github.io/beansreels/workshops.html" data-background-interactive >
					<div style="position: absolute; width: 40%; right: 0; box-shadow: 0 1px 4px rgba(0,0,0,0.5), 0 5px 25px rgba(0,0,0,0.2); background-color: rgba(0, 0, 0, 0.8); color: #fff; padding: 20px; font-size: 20px; text-align: left;">
						<h2>MORE WORKSHOPS</h2>
						<p>En mi repositorio personal podéis encontrar mas manuales y guías sobre otros workshops</p>
					</div>
				</section>

			<section style="text-align: left;">
					<h1 >THE END</h1>
					<p>
						- <a href = "mailto: eduardochamorromartin@gmail.com">Send me an Email</a> <br>
						- <a href="https://github.com/EDUARDOCHAMORRO/">Source code &amp; documentation</a>
					</p>
			</section>


			</div>
		</div>

		<script src="lib/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				controls: true,
				progress: true,
				center: true,
				hash: true,
				transition: 'slide', //None - Fade - Slide - Convex - Concave - Zoom
				dependencies: [
					{ src: 'lib/marked.js' },
					{ src: 'lib/markdown.js' },
					{ src: 'lib/search.js', async: true },
					{ src: 'lib/zoom.js', async: true },
					{ src: 'lib/notes.js', async: true },
					{ src: 'lib/highlight.js', async: true }
				]
			});
		</script>
	</body>
</html>
